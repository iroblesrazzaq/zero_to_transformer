{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Assignment - Tier 1 (Assisted Implementation)\n",
    "# Zero to Transformer - Week 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# always use this torch code to use gpu if possible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess the MNIST dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # normalize to mean, std of MNIST\n",
    "])\n",
    "\n",
    "# Load the training dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Load the test dataset\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_samples(dataloader, num_samples=5):\n",
    "    \"\"\"Display some sample images from the dataset\"\"\"\n",
    "    examples = iter(dataloader)\n",
    "    images, labels = next(examples)\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(1, num_samples, i+1)\n",
    "        plt.imshow(images[i][0].numpy(), cmap='gray')\n",
    "        plt.title(f'Label: {labels[i].item()}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_samples(train_loader) # comment out if don't want to visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Multi-Layer Perceptron (MLP) model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, num_classes):\n",
    "        \"\"\"\n",
    "        Initialize the MLP model.\n",
    "        \n",
    "        Args:\n",
    "            input_size (int): Size of the input features\n",
    "            hidden_size1 (int): Size of the first hidden layer\n",
    "            hidden_size2 (int): Size of the second hidden layer\n",
    "            num_classes (int): Number of output classes\n",
    "        \"\"\"\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # TODO: Define the layers of the network\n",
    "        # Layer 1: Input layer to first hidden layer with ReLU activation\n",
    "        self.layer1 = nn.Sequential(\n",
    "            # YOUR CODE HERE: Create a linear layer from input_size to hidden_size1\n",
    "            nn.Linear(input_size, hidden_size1),\n",
    "            # YOUR CODE HERE: Add a ReLU activation function\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Layer 2: First hidden layer to second hidden layer with ReLU activation\n",
    "        self.layer2 = nn.Sequential(\n",
    "            # YOUR CODE HERE: Create a linear layer from hidden_size1 to hidden_size2\n",
    "            # YOUR CODE HERE: Add a ReLU activation function\n",
    "        )\n",
    "        \n",
    "        # Layer 3: Second hidden layer to output layer (no activation, will be applied in loss function)\n",
    "        # YOUR CODE HERE: Create a linear layer from hidden_size2 to num_classes\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape [batch_size, input_size]\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        # TODO: Implement the forward pass\n",
    "        # Flatten the input image\n",
    "        # YOUR CODE HERE: Reshape x from [batch_size, 1, 28, 28] to [batch_size, 784]\n",
    "        \n",
    "        # Pass through layer 1\n",
    "        # YOUR CODE HERE: Pass x through the first layer\n",
    "        \n",
    "        # Pass through layer 2\n",
    "        # YOUR CODE HERE: Pass x through the second layer\n",
    "        \n",
    "        # Pass through output layer\n",
    "        # YOUR CODE HERE: Pass x through the output layer\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_size = 28 * 28  # MNIST images are 28x28 pixels\n",
    "hidden_size1 = 256\n",
    "hidden_size2 = 128\n",
    "num_classes = 10      # 10 digits (0-9)\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_size, hidden_size1, hidden_size2, num_classes).to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    \"\"\"\n",
    "    Train the model.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The neural network model\n",
    "        train_loader (DataLoader): DataLoader for training data\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimization algorithm\n",
    "        num_epochs (int): Number of training epochs\n",
    "    \n",
    "    Returns:\n",
    "        list: Training losses for each epoch\n",
    "    \"\"\"\n",
    "    model.train()  # Set the model to training mode\n",
    "    train_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            # Move tensors to the configured device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # TODO: Implement the training step\n",
    "            # YOUR CODE HERE: Clear the gradients\n",
    "            \n",
    "            # Forward pass\n",
    "            # YOUR CODE HERE: Get the outputs from the model\n",
    "            \n",
    "            # Calculate loss\n",
    "            # YOUR CODE HERE: Calculate the loss using criterion, outputs, and labels\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            # YOUR CODE HERE: Backpropagate the loss\n",
    "            # YOUR CODE HERE: Update the parameters\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Print statistics every 100 batches\n",
    "            if (i+1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "        # Record the average loss for this epoch\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "    \n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test data.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The neural network model\n",
    "        test_loader (DataLoader): DataLoader for test data\n",
    "    \n",
    "    Returns:\n",
    "        float: Accuracy of the model on the test data\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # TODO: Implement the evaluation step\n",
    "            # YOUR CODE HERE: Get the outputs from the model\n",
    "            \n",
    "            # Get the predicted class (index with highest value)\n",
    "            # YOUR CODE HERE: Get the predicted class indices\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_losses):\n",
    "    \"\"\"Plot the training loss over epochs\"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, marker='o')\n",
    "    plt.title('Training Loss vs. Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save model, uncomment and run:\n",
    "# torch.save(model.state_dict(), 'mlp_model.pth')\n",
    "# print(\"Model saved to 'mlp_model.pth'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
